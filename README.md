
*********************************************************************************************************************

 Supplementary Python and Jupyter Files for Lecturers of the IU-Course on "Introduction to Data Science" (2023/2024) 
	
*********************************************************************************************************************
										    	       	
 	Copyright : IU Internationale Hochschule GmbH, Juri-Gagarin-Ring 152, D-99084 Erfurt	       		 
										    	       	
*********************************************************************************************************************

Datenwissenschaftliche Grundlagen in Python :

*********************************************************************************************************************

	1.1 : Berechnung einer Cosinusfunktion
	1.2 : Erstellen einer Tabelle mit Pandas
	1.3 : Illustration einer Standard IF-Abfrage (Lohngruppen)
	1.4 : Illustration des Aufbaus künstlicher Intelligenz aus 1.3
	1.5 : Matrixmultiplikation mit MapReduce
	1.6 : Berechnung von Eigenwerten
	1.7 : Ableitung einer tanh-Funktion
	1.8 : Wellenpaket aus einer tanh-Funktion
	1.9 : Maximal- und Minimalwerte der tanh-Funktion
	1.10 : Minimierung der Lernrate (Englisch: Learning Rate)
	1.11 : Gaußsche Zufallsvariablen
	1.12 : Modellierung von Zufallszahlen
	1.13 : Matrixnormierung
	1.14 : Berechnung der Kreiszahl Pi mit PySpark
	1.15 : Berechnung der Kreiszahl Pi mit parallelem Algorithmus 

*********************************************************************************************************************

	Bearbeitung und Darstellungen von Daten in Python :

*********************************************************************************************************************

	2.1 : Import von Primärdaten	
	2.2 : Auswertung eines Metadatensatzes
	2.3 :  Berechnung der Genauigkeitvon externen Daten	
	2.4 : Bestimmung der numerischen Abweichungen bei der Berechnung von Pi.	
	2.5 : Überlagertes Quantisiertes Feld
	2.6 : Zwei-dimensionale lineare Interpolation
	2.7 : Vergleich von Vektor- und polynomieller Regression	
	2.8 : Robust Variance, OneClassSVM, Isolation Forest, Local Outliers
	2.9 : Analyse der Genauigkeit von Gesichterkennung per PCA (randomized SVC)
	2.10 : Diskretisierung von zwei-dimensionalen Daten

*********************************************************************************************************************

	Analyse und Klassifizierung von Daten in Python :

*********************************************************************************************************************

	3.1 : Anwendung von Pandas, Loc and iLoc		       
	3.2 : ROC-Diagramm für ein zwei Klassenproblem 
	3.3 : Berchnung der Gewinne aus einer Lotterie      
	3.4 : Analyse von Netzwerkgraphen    

*********************************************************************************************************************

	Klassische und Bayes'sche Statistik in Python :

*********************************************************************************************************************

	4.1 : Berechnung von Gewinnen aus der Monty Hall Strategie	     
	4.2 : Numerische Approximation von Zufallsgrößen
	4.3 : Berechnung der Kovarianz mit Pandas und NumPy 				     
	4.4 : Maß von Kendall, Pearson und Spearman   

*********************************************************************************************************************

	Komplexe AI-Modelle in Python :

*********************************************************************************************************************

	5.1 : Analyse und Klassifizerung eines zwei-komponentigen Datensatzes
	5.2 : Hauptkomponentenanalyse
	5.3 : Exakte, inkrementelle und zufällige PCA			 
	5.4 : Kernel Hauptkomponentenanalyse 
	5.5 : Sparse Coding vs. Dictionary Learning		 
	5.6 : Faktorenanalyse im IRIS-Datensatz	
	5.7 : Zerlegung eines gemischtes Siganls in Einzelkomponenten mittels PCA	 
	5.8 : Analyse von Textinhalten	

*********************************************************************************************************************

	The same for Jupyter files, which are labeled with notebook_example_a_x.ipynb (where a = 1...5, and x variable).

	Password for zip-files associated to the lecture series "Introduction to Data Science" can be received 
	at alexej.schelle.ext@iu.org.

	References to AI methods and standards can be found with the different Python files.

*********************************************************************************************************************
